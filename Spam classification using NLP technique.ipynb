{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2adafa6-8690-4e43-a0d5-b2e56f4880da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Install NLTK if not installed\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download ('punkt_tab')\n",
    "nltk.download ('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2ac8871-274a-42df-8666-f88c62661176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a paragraph from Gates notes and using it as a corpus: Thursday, May8, 2025:\n",
    "# Note: Every row in a corpus is called as a document and every word in a document is called as a term.\n",
    "\n",
    "corpus = [\"That is why I have decided to give my money back to society much faster\",\n",
    "          \"than I had originally planned\",\n",
    "          \"I will give away virtually all my wealth through the Gates Foundation over the next 20 years\",\n",
    "          \"to the cause of saving and improving lives around the world\",\n",
    "          \"And on December 31, 2045, the foundation will close its doors permanently\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1b956-a5fd-4137-958b-705e2def0a7e",
   "metadata": {},
   "source": [
    "### Using Bag Of Words approach to create a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af5bf52b-8db3-4f0c-8b21-792a12ff5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above approach converts a collection of text documents into a bag-of-words representation, \n",
    "# where each unique word becomes a feature (column), and its value is the count of times that word appears in each document.\n",
    "# CountVectoriser helps us in this operation by:\n",
    "                                                # Tokenizing the text (splits it into words).\n",
    "                                                # Rows = documents\n",
    "                                                # Columns = words in the vocabulary\n",
    "                                                # Cell values = count of each word in that document, represented by cell(i,j) where\n",
    "# j is the number of times the term appearrs in a documnet 'i'\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e7d1fbb-556a-4446-a6d1-fd0a1a629263",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd00ec05-052d-4558-ab47-126a0eb8a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b068564-691f-4e72-84cb-6336a4eaadff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x46 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 54 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data\n",
    "# In the vectorized_data sparse matrix only 54 non-zero entries exist. Remaining 176 out of 230 are zeros. \n",
    "# sparse matriz ensures computation is faster and memory usage is less"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9ac12-d6a3-493f-8103-c439cdb95ece",
   "metadata": {},
   "source": [
    "### Getting number of columns or unique words in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "783ce29b-ecba-40ca-b09e-c092abd1d4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20', '2045', '31', 'all', 'and', 'around', 'away', 'back',\n",
       "       'cause', 'close', 'december', 'decided', 'doors', 'faster',\n",
       "       'foundation', 'gates', 'give', 'had', 'have', 'improving', 'is',\n",
       "       'its', 'lives', 'money', 'much', 'my', 'next', 'of', 'on',\n",
       "       'originally', 'over', 'permanently', 'planned', 'saving',\n",
       "       'society', 'than', 'that', 'the', 'through', 'to', 'virtually',\n",
       "       'wealth', 'why', 'will', 'world', 'years'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4ee3d-241d-4144-a6b8-ef3548c58296",
   "metadata": {},
   "source": [
    "### Creating a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "682ae999-422b-40b4-b21c-67b693413dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>2045</th>\n",
       "      <th>31</th>\n",
       "      <th>all</th>\n",
       "      <th>and</th>\n",
       "      <th>around</th>\n",
       "      <th>away</th>\n",
       "      <th>back</th>\n",
       "      <th>cause</th>\n",
       "      <th>close</th>\n",
       "      <th>...</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>through</th>\n",
       "      <th>to</th>\n",
       "      <th>virtually</th>\n",
       "      <th>wealth</th>\n",
       "      <th>why</th>\n",
       "      <th>will</th>\n",
       "      <th>world</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   20  2045  31  all  and  around  away  back  cause  close  ...  that  the  \\\n",
       "0   0     0   0    0    0       0     0     1      0      0  ...     1    0   \n",
       "1   0     0   0    0    0       0     0     0      0      0  ...     0    0   \n",
       "2   1     0   0    1    0       0     1     0      0      0  ...     0    2   \n",
       "3   0     0   0    0    1       1     0     0      1      0  ...     0    2   \n",
       "4   0     1   1    0    1       0     0     0      0      1  ...     0    1   \n",
       "\n",
       "   through  to  virtually  wealth  why  will  world  years  \n",
       "0        0   2          0       0    1     0      0      0  \n",
       "1        0   0          0       0    0     0      0      0  \n",
       "2        1   0          1       1    0     1      0      1  \n",
       "3        0   1          0       0    0     0      1      0  \n",
       "4        0   0          0       0    0     1      0      0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(vectorized_data.toarray(), columns = cv.get_feature_names_out())\n",
    "data\n",
    "\n",
    "#NOte: # Pandas DataFrame can't directly display or manipulate sparse matrices. Hence, converting it into array is essential.\n",
    "# toarray() converts the sparse matrix into a dense NumPy array to creates a full matrix where all zeroes and non-zeroes \n",
    "# are shown explicitly. This dense array can then be passed cleanly into pd.DataFrame(...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf3b2a-e1b9-4adf-9672-7cff3cecb4cd",
   "metadata": {},
   "source": [
    "### A brief overview on scaling techniques in NLP\n",
    "We can use Stemming, Lemmatization or Regular Expression - based removals(later in the part).\n",
    "\n",
    "STEMMING\n",
    "Reduces words to their root form by chopping off suffixes (e.g., \"playing\" → \"play\", \"better\" → \"better\").\n",
    "It’s fast but can be crude (e.g., \"studies\" → \"studi\").\n",
    "\n",
    "LEMMATIZATION \n",
    "Also reduces words to their base form, but uses vocabulary and grammar (e.g., \"was\" → \"be\", \"better\" → \"good\").\n",
    "More accurate than stemming but slower.Useful when linguistic correctness matters.\n",
    "\n",
    "REGEX-BASED REMOVALS\n",
    "Uses regular expressions to remove or extract patterns like: \n",
    "                                                           # Punctuation \n",
    "                                                           # Numbers\n",
    "                                                           # HTML tags\n",
    "                                                           # URLs\n",
    "                                                           # Emojis\n",
    "                                                           # Extra spaces\n",
    "Essential for cleaning noisy or unstructured text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f84c983-a867-4f65-b977-08eee0fc67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f16d049-613d-4072-a6d9-3886001f97fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amaz\n",
      "amaz\n",
      "amazingli\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('amazement'))\n",
    "print(ps.stem('amazing'))\n",
    "print(ps.stem('amazingly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fc00cd05-a6a3-46f0-81bd-99eb39eacde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9bb5319c-52bb-4615-b00f-54805b719710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choke\n",
      "choking\n",
      "chokingly\n"
     ]
    }
   ],
   "source": [
    "print(wl.lemmatize('choke', pos = 'n')) # Noun\n",
    "print(wl.lemmatize('choking', pos = 'r')) # Adjective\n",
    "print(wl.lemmatize('chokingly', pos = 's')) # Adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59f3ed83-28c7-41d0-8c27-afedc35f68a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('give', 'VB'),\n",
       " ('away', 'RP'),\n",
       " ('virtually', 'RB'),\n",
       " ('all', 'DT'),\n",
       " ('my', 'PRP$'),\n",
       " ('wealth', 'NN'),\n",
       " ('through', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Gates', 'NNP'),\n",
       " ('Foundation', 'NNP'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('next', 'JJ'),\n",
       " ('20', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('cause', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('saving', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('improving', 'VBG'),\n",
       " ('lives', 'NNS'),\n",
       " ('around', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using tagging for a sentence\n",
    "pos_tag(word_tokenize('I will give away virtually all my wealth through the Gates Foundation over the next 20 years to the cause of saving and improving lives around the world'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9373a2e-2dd6-4639-a659-b719e59ac639",
   "metadata": {},
   "source": [
    "### Spam classification using NLP technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43ed8e6a-12aa-45fc-a5fb-c479a059d2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text Unnamed: 2  \\\n",
       "0       ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1       ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3       ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...     ...                                                ...        ...   \n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568    ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569    ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570    ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571    ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('spam.csv', encoding = 'latin')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ce284e6-b909-480e-9f12-c986613c7051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham              Will Ì_ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use only 2 columns for our dataset: 'Target' and 'Text'\n",
    "dataset = dataset[['Target', 'Text']]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f6c89-7df8-410c-9d75-994a666de677",
   "metadata": {},
   "source": [
    "### Creating a sparse Document Term matrix of the above dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a530f5a0-e1a4-4829-af06-764937babcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CountVectorizer(min_df = 10, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f0eddc9-dfe0-4f12-9307-141f2219bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_dataset = CV.fit_transform(dataset['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9eb0bac-dc86-4657-abaa-07da768591c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x833 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27978 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1024f998-e78b-4015-8a54-0ef8977c09cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '03', '04', '0800', '08000839402', '08000930705',\n",
       "       '10', '100', '1000', '10p', '11', '12', '12hrs', '150', '150p',\n",
       "       '150ppm', '16', '18', '1st', '20', '200', '2000', '2003', '250',\n",
       "       '2lands', '2nd', '2nite', '30', '350', '50', '500', '5000', '750',\n",
       "       '800', '8007', '86688', '87066', '900', 'abiola', 'able', 'abt',\n",
       "       'ac', 'account', 'actually', 'address', 'admirer', 'aft',\n",
       "       'afternoon', 'age', 'ago', 'ah', 'aight', 'alright', 'amp',\n",
       "       'angry', 'ans', 'answer', 'anytime', 'apply', 'ard', 'area',\n",
       "       'asap', 'ask', 'askd', 'asked', 'asking', 'ass', 'attempt',\n",
       "       'auction', 'available', 'await', 'award', 'awarded', 'away',\n",
       "       'awesome', 'b4', 'babe', 'baby', 'bad', 'balance', 'bank', 'bath',\n",
       "       'bathe', 'bcoz', 'beautiful', 'bed', 'believe', 'best', 'better',\n",
       "       'big', 'birthday', 'bit', 'blue', 'bonus', 'book', 'booked',\n",
       "       'bored', 'bout', 'box', 'boy', 'boytoy', 'break', 'bring',\n",
       "       'brother', 'bslvyl', 'bt', 'bus', 'busy', 'buy', 'call2optout',\n",
       "       'called', 'caller', 'calling', 'calls', 'camcorder', 'came',\n",
       "       'camera', 'car', 'card', 'care', 'carlos', 'case', 'cash', 'cause',\n",
       "       'chance', 'change', 'charge', 'charged', 'chat', 'cheap', 'check',\n",
       "       'checking', 'chennai', 'chikku', 'choose', 'christmas', 'claim',\n",
       "       'class', 'clean', 'close', 'club', 'code', 'collect', 'collection',\n",
       "       'college', 'colour', 'com', 'come', 'comes', 'comin', 'coming',\n",
       "       'comp', 'company', 'complimentary', 'computer', 'confirm',\n",
       "       'congrats', 'congratulations', 'contact', 'content', 'convey',\n",
       "       'cool', 'correct', 'cos', 'cost', 'couple', 'course', 'coz',\n",
       "       'crave', 'crazy', 'credit', 'cs', 'cum', 'currently', 'custcare',\n",
       "       'customer', 'cut', 'da', 'dad', 'darlin', 'darren', 'dat', 'date',\n",
       "       'dating', 'day', 'days', 'dear', 'decided', 'decimal', 'deep',\n",
       "       'del', 'delivery', 'den', 'details', 'did', 'didn', 'didnt', 'die',\n",
       "       'different', 'difficult', 'dinner', 'direct', 'dis', 'discount',\n",
       "       'dnt', 'does', 'doesn', 'doin', 'doing', 'don', 'dont', 'double',\n",
       "       'download', 'draw', 'dream', 'dreams', 'drink', 'drive', 'driving',\n",
       "       'drop', 'drugs', 'dude', 'dun', 'dunno', 'earlier', 'early',\n",
       "       'easy', 'eat', 'eh', 'em', 'email', 'end', 'ends', 'enjoy',\n",
       "       'enter', 'entered', 'entry', 'eve', 'evening', 'ex', 'exam',\n",
       "       'expires', 'extra', 'face', 'fact', 'family', 'fancy', 'fantastic',\n",
       "       'far', 'fast', 'feel', 'feeling', 'felt', 'film', 'final',\n",
       "       'finally', 'fine', 'finish', 'finished', 'fone', 'food', 'forget',\n",
       "       'forgot', 'fr', 'free', 'freemsg', 'fri', 'friday', 'friend',\n",
       "       'friends', 'friendship', 'frm', 'frnd', 'frnds', 'fuck', 'fucking',\n",
       "       'fun', 'game', 'games', 'gas', 'gave', 'gd', 'ge', 'gets',\n",
       "       'getting', 'getzed', 'gift', 'girl', 'girls', 'glad', 'god',\n",
       "       'goes', 'goin', 'going', 'gone', 'gonna', 'good', 'goodmorning',\n",
       "       'got', 'gotta', 'gr8', 'great', 'grins', 'gt', 'guaranteed', 'gud',\n",
       "       'guess', 'guy', 'guys', 'gym', 'ha', 'haf', 'haha', 'hair', 'half',\n",
       "       'hand', 'happen', 'happened', 'happiness', 'happy', 'hard', 'hav',\n",
       "       'haven', 'havent', 'having', 'head', 'hear', 'heard', 'heart',\n",
       "       'hee', 'hello', 'help', 'hey', 'hg', 'hi', 'hit', 'hmm', 'hmmm',\n",
       "       'hold', 'holiday', 'home', 'hope', 'hospital', 'hot', 'hour',\n",
       "       'hours', 'house', 'hows', 'http', 'huh', 'hungry', 'hurt', 'id',\n",
       "       'identifier', 'il', 'ill', 'im', 'immediately', 'important',\n",
       "       'india', 'info', 'information', 'invited', 'ipod', 'isn', 'jay',\n",
       "       'job', 'join', 'jus', 'just', 'juz', 'kate', 'kind', 'kiss',\n",
       "       'knew', 'know', 'knows', 'knw', 'land', 'landline', 'laptop',\n",
       "       'lar', 'late', 'later', 'latest', 'laugh', 'ldn', 'leave',\n",
       "       'leaves', 'leaving', 'left', 'leh', 'lei', 'lesson', 'let', 'lets',\n",
       "       'liao', 'life', 'light', 'like', 'line', 'link', 'listen',\n",
       "       'little', 'live', 'll', 'loads', 'log', 'lol', 'long', 'look',\n",
       "       'looking', 'lor', 'lose', 'lost', 'lot', 'lots', 'lovable', 'love',\n",
       "       'loved', 'lovely', 'loving', 'lt', 'luck', 'lucky', 'lunch', 'luv',\n",
       "       'mah', 'mail', 'make', 'makes', 'making', 'man', 'march', 'match',\n",
       "       'mate', 'mates', 'mayb', 'maybe', 'mean', 'means', 'meant', 'meet',\n",
       "       'meeting', 'merry', 'message', 'messages', 'met', 'min', 'mind',\n",
       "       'mins', 'minute', 'minutes', 'miss', 'missed', 'missing', 'mm',\n",
       "       'mob', 'mobile', 'mobiles', 'mobileupd8', 'mom', 'moment',\n",
       "       'monday', 'money', 'month', 'months', 'morning', 'motorola',\n",
       "       'movie', 'mr', 'mrng', 'msg', 'msgs', 'mu', 'mum', 'music', 'muz',\n",
       "       'na', 'nah', 'national', 'need', 'needs', 'net', 'network', 'neva',\n",
       "       'new', 'news', 'ni8', 'nice', 'night', 'nite', 'noe', 'nokia',\n",
       "       'nope', 'normal', 'nt', 'ntt', 'number', 'numbers', 'nyt', 'offer',\n",
       "       'offers', 'office', 'oh', 'ok', 'okay', 'okie', 'old', 'online',\n",
       "       'oops', 'open', 'operator', 'opt', 'orange', 'orchard', 'order',\n",
       "       'oredi', 'oso', 'outside', 'pa', 'pain', 'parents', 'park',\n",
       "       'party', 'pass', 'pay', 'people', 'person', 'pete', 'phone',\n",
       "       'phones', 'pic', 'pick', 'picking', 'pics', 'place', 'plan',\n",
       "       'plans', 'play', 'player', 'pls', 'plus', 'plz', 'pm', 'po',\n",
       "       'pobox', 'point', 'points', 'poly', 'post', 'pounds', 'pray',\n",
       "       'press', 'pretty', 'price', 'princess', 'private', 'prize', 'prob',\n",
       "       'probably', 'problem', 'project', 'pub', 'question', 'questions',\n",
       "       'quite', 'quiz', 'rakhesh', 'rate', 'rates', 'reach', 'reached',\n",
       "       'read', 'reading', 'ready', 'real', 'really', 'reason', 'receive',\n",
       "       'red', 'redeemed', 'remember', 'remove', 'rental', 'reply',\n",
       "       'representative', 'rest', 'reveal', 'right', 'ring', 'ringtone',\n",
       "       'rite', 'room', 'row', 'rply', 'rs', 'run', 'sad', 'sae', 'safe',\n",
       "       'said', 'sat', 'saturday', 'save', 'saw', 'say', 'saying', 'says',\n",
       "       'sch', 'school', 'sea', 'search', 'second', 'secret', 'seeing',\n",
       "       'seen', 'selected', 'semester', 'send', 'sending', 'sent',\n",
       "       'service', 'services', 'set', 'sex', 'sexy', 'shall', 'shit',\n",
       "       'shop', 'shopping', 'shower', 'shows', 'simple', 'sir', 'sis',\n",
       "       'sister', 'sleep', 'sleeping', 'slow', 'slowly', 'small', 'smile',\n",
       "       'smiling', 'smoke', 'sms', 'smth', 'snow', 'somebody', 'song',\n",
       "       'sony', 'soon', 'sorry', 'sort', 'sound', 'sounds', 'speak',\n",
       "       'special', 'spend', 'st', 'start', 'started', 'statement', 'stay',\n",
       "       'std', 'stop', 'store', 'story', 'study', 'stuff', 'stupid', 'sub',\n",
       "       'suite342', 'sun', 'sunday', 'support', 'supposed', 'sure',\n",
       "       'surprise', 'sweet', 'swing', 'takes', 'taking', 'talk', 'talking',\n",
       "       'tc', 'tel', 'tell', 'telling', 'terms', 'test', 'text', 'texts',\n",
       "       'th', 'thank', 'thanks', 'thanx', 'thats', 'thing', 'things',\n",
       "       'think', 'thinking', 'thinks', 'thk', 'tho', 'thought', 'tickets',\n",
       "       'til', 'till', 'time', 'times', 'tired', 'tmr', 'today', 'todays',\n",
       "       'told', 'tomo', 'tomorrow', 'tone', 'tones', 'tonight', 'took',\n",
       "       'tot', 'touch', 'town', 'treat', 'tried', 'trip', 'true', 'truth',\n",
       "       'try', 'trying', 'ts', 'tv', 'txt', 'txting', 'txts', 'type',\n",
       "       'ugh', 'uk', 'uncle', 'understand', 'unlimited', 'unsubscribe',\n",
       "       'update', 'ur', 'urgent', 'use', 'used', 'usf', 'usual', 'valid',\n",
       "       'valued', 've', 'video', 'visit', 'voice', 'voucher', 'vouchers',\n",
       "       'w1j6hl', 'wait', 'waiting', 'wake', 'walk', 'wan', 'wana',\n",
       "       'wanna', 'want', 'wanted', 'wants', 'warm', 'wasn', 'wat', 'watch',\n",
       "       'watching', 'water', 'way', 'week', 'weekend', 'weekly', 'weeks',\n",
       "       'welcome', 'wen', 'went', 'whats', 'wid', 'wif', 'wife', 'wil',\n",
       "       'win', 'wine', 'winner', 'wish', 'wishing', 'wit', 'wk', 'wkly',\n",
       "       'woke', 'won', 'wonder', 'wonderful', 'wont', 'word', 'words',\n",
       "       'work', 'working', 'world', 'worried', 'worry', 'worth', 'wot',\n",
       "       'wow', 'write', 'wrong', 'www', 'xmas', 'xx', 'xxx', 'ya', 'yar',\n",
       "       'yeah', 'year', 'years', 'yep', 'yes', 'yesterday', 'yo', 'yr',\n",
       "       'yup', 'ì_', 'ìï', 'û_'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30502d32-374d-4ad6-bdac-7b12f272ff4d",
   "metadata": {},
   "source": [
    "### Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28669e04-7bca-46ba-8cb5-99d92f34d101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham              Will Ì_ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(vectorized_dataset.toarray(), columns = CV.get_feature_names_out())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dca86a39-d635-437f-b27a-72c4fd6cc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7415cf96-b1d0-46df-bb2f-a13ec9a187ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting special characters and digits using Regular Expression-based removals\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "489321af-8b14-4211-b31a-b53e0ddbedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_characters(input_sent):\n",
    "    pattern = '[^a-zA-z0-9\\s]'\n",
    "    return len(re.findall(pattern, input_sent))/len(input_sent)\n",
    "\n",
    "# Calculates the ratio of special characters to the total message length. becauses,\n",
    "# spam messages often contain more special symbols (for attention-grabbing or obfuscation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1715ee-81c3-4339-9afe-162ffca72df2",
   "metadata": {},
   "source": [
    "#### pattern = '[^a-zA-Z0-9\\s]' means this pattern matches any character that is NOT: \n",
    "                                   # 1. a lowercase or uppercase letter (a-zA-Z)\n",
    "                                   # 2. a digit (0-9)\n",
    "                                   # 3. whitespace (\\s)\n",
    "                                   # The ^ inside the square brackets means \"not\".\n",
    "                                   # Purpose: To capture special characters (like @, #, !, ', &, (, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ad9bf9e7-e6f6-4f96-804a-956d53fa3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_extraction(input_sent):\n",
    "    pattern = '[0-9]'\n",
    "    return len(re.findall(pattern, input_sent))/len(input_sent)\n",
    "\n",
    "    # Calculates the ratio of digits to the total message length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "874fb5d5-3867-4bb9-900c-9970c219d928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.081081\n",
       "1       0.206897\n",
       "2       0.038710\n",
       "3       0.122449\n",
       "4       0.032787\n",
       "          ...   \n",
       "5567    0.062112\n",
       "5568    0.054054\n",
       "5569    0.122807\n",
       "5570    0.008000\n",
       "5571    0.038462\n",
       "Name: Text, Length: 5572, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Text'].apply(lambda x:special_characters(x))\n",
    "# dataset['Text']: Accesses the 'Text' column in the dataset DataFrame, which contains text data\n",
    "# .apply(lambda x: ...): Applies a function to each value x (i.e., each message) in the 'Text' column.\n",
    "# special_characters(x): Calls the custom function that calculates the proportion of special characters in the text x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d94015a1-c73e-483e-b278-03a7771c8d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000000\n",
       "1       0.000000\n",
       "2       0.161290\n",
       "3       0.000000\n",
       "4       0.000000\n",
       "          ...   \n",
       "5567    0.130435\n",
       "5568    0.000000\n",
       "5569    0.000000\n",
       "5570    0.000000\n",
       "5571    0.000000\n",
       "Name: Text, Length: 5572, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Text'].apply(lambda x:digit_extraction(x))\n",
    "# dataset['Text']: Accesses the 'Text' column in the dataset DataFrame, which contains text data\n",
    "# .apply(lambda x: ...): Applies a function to each value x (i.e., each message) in the 'Text' column.\n",
    "# digit_extraction(x): Calls the custom function that calculates the proportion of special characters in the text x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "721212dc-8e42-4502-9c79-b91a25d81b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['special_characters'] = dataset['Text'].apply(lambda x:special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e961e184-0651-48e7-a83a-d7577fcd284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['digit_extraction'] = dataset['Text'].apply(lambda x:digit_extraction(x))\n",
    "\n",
    "# Both lines above apply a function to the 'Text' column of the dataset DataFrame and \n",
    "# save the results in new columns in the X DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d630c6-e0ea-49b8-8916-edfd13cecc2c",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f027078a-fc7c-4a8c-ae6b-833308953a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bbbf3905-2158-4bc9-ae89-4aa133e382f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4efda8ec-9cd2-48d6-a4d7-32bf7ac40b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6497c94b-c03f-4a27-be6d-98fa5efac99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "62142d40-8f90-4642-a004-1a6d717f4f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0921af4c-a393-4ea1-b0ab-8f415f8ca3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1453\n",
      "        spam       0.99      0.90      0.94       219\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.99      0.95      0.97      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
